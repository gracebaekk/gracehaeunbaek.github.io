+++
date = '2025-12-28T00:00:00-07:00'
draft = false
title = 'AgentCorp'
weight = 2
listImage = "images/theagentcompany.png"
image = "images/tac-content.png"
+++

I developed key components for AgentBeats, a comprehensive multi-agent benchmarking platform designed to evaluate Large Language Models (LLMs) on real-world workplace tasks. This project required building sophisticated agent systems that could autonomously handle complex software engineering and project management scenarios.

I specifically built the Green Agent component, which integrates TheAgentCompany benchmark into the platform. This agent orchestrates 175 long-horizon evaluations across various domains, managing complex workflows that test LLM capabilities in realistic workplace environments. I implemented robust task distribution systems, automated environment setup procedures, and checkpoint-based scoring mechanisms to ensure reliable and accurate evaluation results.

I also contributed to the White Agent logic, which focuses on autonomous task execution and multi-tool coordination. This involved designing systems that allow agents to independently navigate complex tasks, make decisions, and coordinate multiple tools and resources effectively. The entire system was containerized using Docker to ensure consistent deployment and execution across different environments.

**Technologies:** Python, Docker

[View Project](https://github.com/gracebaekk/the-agent-company)
